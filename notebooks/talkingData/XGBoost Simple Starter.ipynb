{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_xgb(train, test, features, target, random_state=0):\n",
    "    \n",
    "    eta = 0.025\n",
    "    max_depth = 7\n",
    "    subsample = 0.75\n",
    "    colsample_bytree = 0.75\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 500\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.2\n",
    "    \n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "    \n",
    "    print('Validating...')\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "    \n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "    \n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read app events...\n",
      "Read events...\n",
      "Read brands...\n",
      "Read train...\n",
      "Read test...\n",
      "('Length of train: ', 74645)\n",
      "('Length of test: ', 112071)\n",
      "Features [5]: ['active', 'counts', 'device_model', 'installed', 'phone_brand']\n",
      "XGBoost params. ETA: 0.025, MAX_DEPTH: 7, SUBSAMPLE: 0.75, COLSAMPLE_BY_TREE: 0.75\n",
      "('Length train:', 59716)\n",
      "('Length valid:', 14929)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-mlogloss:2.481809\teval-mlogloss:2.482385\n",
      "[1]\ttrain-mlogloss:2.478796\teval-mlogloss:2.479953\n",
      "[2]\ttrain-mlogloss:2.475611\teval-mlogloss:2.477491\n",
      "[3]\ttrain-mlogloss:2.472672\teval-mlogloss:2.475169\n",
      "[4]\ttrain-mlogloss:2.469894\teval-mlogloss:2.473009\n",
      "[5]\ttrain-mlogloss:2.467013\teval-mlogloss:2.470794\n",
      "[6]\ttrain-mlogloss:2.464253\teval-mlogloss:2.468585\n",
      "[7]\ttrain-mlogloss:2.461714\teval-mlogloss:2.466646\n",
      "[8]\ttrain-mlogloss:2.459087\teval-mlogloss:2.464626\n",
      "[9]\ttrain-mlogloss:2.456849\teval-mlogloss:2.462879\n",
      "[10]\ttrain-mlogloss:2.454268\teval-mlogloss:2.460948\n",
      "[11]\ttrain-mlogloss:2.451678\teval-mlogloss:2.459074\n",
      "[12]\ttrain-mlogloss:2.449282\teval-mlogloss:2.457279\n",
      "[13]\ttrain-mlogloss:2.446924\teval-mlogloss:2.455527\n",
      "[14]\ttrain-mlogloss:2.444714\teval-mlogloss:2.453862\n",
      "[15]\ttrain-mlogloss:2.442546\teval-mlogloss:2.452269\n",
      "[16]\ttrain-mlogloss:2.440429\teval-mlogloss:2.450669\n",
      "[17]\ttrain-mlogloss:2.438228\teval-mlogloss:2.449073\n",
      "[18]\ttrain-mlogloss:2.436084\teval-mlogloss:2.447475\n",
      "[19]\ttrain-mlogloss:2.434093\teval-mlogloss:2.446009\n",
      "[20]\ttrain-mlogloss:2.432047\teval-mlogloss:2.444529\n",
      "[21]\ttrain-mlogloss:2.430047\teval-mlogloss:2.443107\n",
      "[22]\ttrain-mlogloss:2.428092\teval-mlogloss:2.441776\n",
      "[23]\ttrain-mlogloss:2.426185\teval-mlogloss:2.440381\n",
      "[24]\ttrain-mlogloss:2.424294\teval-mlogloss:2.439078\n",
      "[25]\ttrain-mlogloss:2.422498\teval-mlogloss:2.437860\n",
      "[26]\ttrain-mlogloss:2.420766\teval-mlogloss:2.436675\n",
      "[27]\ttrain-mlogloss:2.419008\teval-mlogloss:2.435450\n",
      "[28]\ttrain-mlogloss:2.417350\teval-mlogloss:2.434283\n",
      "[29]\ttrain-mlogloss:2.415632\teval-mlogloss:2.433099\n",
      "[30]\ttrain-mlogloss:2.414005\teval-mlogloss:2.431966\n",
      "[31]\ttrain-mlogloss:2.412462\teval-mlogloss:2.430886\n",
      "[32]\ttrain-mlogloss:2.410932\teval-mlogloss:2.429904\n",
      "[33]\ttrain-mlogloss:2.409284\teval-mlogloss:2.428804\n",
      "[34]\ttrain-mlogloss:2.407789\teval-mlogloss:2.427800\n",
      "[35]\ttrain-mlogloss:2.406235\teval-mlogloss:2.426826\n",
      "[36]\ttrain-mlogloss:2.404693\teval-mlogloss:2.425839\n",
      "[37]\ttrain-mlogloss:2.403306\teval-mlogloss:2.424950\n",
      "[38]\ttrain-mlogloss:2.401855\teval-mlogloss:2.424076\n",
      "[39]\ttrain-mlogloss:2.400467\teval-mlogloss:2.423183\n",
      "[40]\ttrain-mlogloss:2.399077\teval-mlogloss:2.422307\n",
      "[41]\ttrain-mlogloss:2.397734\teval-mlogloss:2.421451\n",
      "[42]\ttrain-mlogloss:2.396383\teval-mlogloss:2.420583\n",
      "[43]\ttrain-mlogloss:2.395033\teval-mlogloss:2.419779\n",
      "[44]\ttrain-mlogloss:2.393650\teval-mlogloss:2.418924\n",
      "[45]\ttrain-mlogloss:2.392387\teval-mlogloss:2.418181\n",
      "[46]\ttrain-mlogloss:2.391116\teval-mlogloss:2.417429\n",
      "[47]\ttrain-mlogloss:2.389941\teval-mlogloss:2.416708\n",
      "[48]\ttrain-mlogloss:2.388635\teval-mlogloss:2.415933\n",
      "[49]\ttrain-mlogloss:2.387495\teval-mlogloss:2.415297\n",
      "[50]\ttrain-mlogloss:2.386333\teval-mlogloss:2.414671\n",
      "[51]\ttrain-mlogloss:2.385211\teval-mlogloss:2.414023\n",
      "[52]\ttrain-mlogloss:2.384050\teval-mlogloss:2.413357\n",
      "[53]\ttrain-mlogloss:2.382919\teval-mlogloss:2.412731\n",
      "[54]\ttrain-mlogloss:2.381800\teval-mlogloss:2.412055\n",
      "[55]\ttrain-mlogloss:2.380753\teval-mlogloss:2.411510\n",
      "[56]\ttrain-mlogloss:2.379661\teval-mlogloss:2.410897\n",
      "[57]\ttrain-mlogloss:2.378601\teval-mlogloss:2.410321\n",
      "[58]\ttrain-mlogloss:2.377617\teval-mlogloss:2.409777\n",
      "[59]\ttrain-mlogloss:2.376595\teval-mlogloss:2.409262\n",
      "[60]\ttrain-mlogloss:2.375561\teval-mlogloss:2.408753\n",
      "[61]\ttrain-mlogloss:2.374545\teval-mlogloss:2.408231\n",
      "[62]\ttrain-mlogloss:2.373618\teval-mlogloss:2.407804\n",
      "[63]\ttrain-mlogloss:2.372821\teval-mlogloss:2.407361\n",
      "[64]\ttrain-mlogloss:2.371895\teval-mlogloss:2.406896\n",
      "[65]\ttrain-mlogloss:2.370976\teval-mlogloss:2.406443\n",
      "[66]\ttrain-mlogloss:2.370116\teval-mlogloss:2.406008\n",
      "[67]\ttrain-mlogloss:2.369211\teval-mlogloss:2.405576\n",
      "[68]\ttrain-mlogloss:2.368345\teval-mlogloss:2.405168\n",
      "[69]\ttrain-mlogloss:2.367450\teval-mlogloss:2.404720\n",
      "[70]\ttrain-mlogloss:2.366634\teval-mlogloss:2.404341\n",
      "[71]\ttrain-mlogloss:2.365742\teval-mlogloss:2.403927\n",
      "[72]\ttrain-mlogloss:2.364912\teval-mlogloss:2.403526\n",
      "[73]\ttrain-mlogloss:2.364023\teval-mlogloss:2.403171\n",
      "[74]\ttrain-mlogloss:2.363228\teval-mlogloss:2.402814\n",
      "[75]\ttrain-mlogloss:2.362382\teval-mlogloss:2.402468\n",
      "[76]\ttrain-mlogloss:2.361521\teval-mlogloss:2.402094\n",
      "[77]\ttrain-mlogloss:2.360687\teval-mlogloss:2.401717\n",
      "[78]\ttrain-mlogloss:2.359945\teval-mlogloss:2.401393\n",
      "[79]\ttrain-mlogloss:2.359228\teval-mlogloss:2.401081\n",
      "[80]\ttrain-mlogloss:2.358458\teval-mlogloss:2.400744\n",
      "[81]\ttrain-mlogloss:2.357722\teval-mlogloss:2.400475\n",
      "[82]\ttrain-mlogloss:2.357013\teval-mlogloss:2.400164\n",
      "[83]\ttrain-mlogloss:2.356302\teval-mlogloss:2.399911\n",
      "[84]\ttrain-mlogloss:2.355579\teval-mlogloss:2.399617\n",
      "[85]\ttrain-mlogloss:2.354800\teval-mlogloss:2.399280\n",
      "[86]\ttrain-mlogloss:2.354065\teval-mlogloss:2.399036\n",
      "[87]\ttrain-mlogloss:2.353297\teval-mlogloss:2.398766\n",
      "[88]\ttrain-mlogloss:2.352615\teval-mlogloss:2.398504\n",
      "[89]\ttrain-mlogloss:2.351938\teval-mlogloss:2.398252\n",
      "[90]\ttrain-mlogloss:2.351278\teval-mlogloss:2.398012\n",
      "[91]\ttrain-mlogloss:2.350589\teval-mlogloss:2.397769\n",
      "[92]\ttrain-mlogloss:2.349932\teval-mlogloss:2.397493\n",
      "[93]\ttrain-mlogloss:2.349322\teval-mlogloss:2.397253\n",
      "[94]\ttrain-mlogloss:2.348720\teval-mlogloss:2.397021\n",
      "[95]\ttrain-mlogloss:2.348067\teval-mlogloss:2.396801\n",
      "[96]\ttrain-mlogloss:2.347465\teval-mlogloss:2.396598\n",
      "[97]\ttrain-mlogloss:2.346842\teval-mlogloss:2.396432\n",
      "[98]\ttrain-mlogloss:2.346235\teval-mlogloss:2.396234\n",
      "[99]\ttrain-mlogloss:2.345590\teval-mlogloss:2.395965\n",
      "[100]\ttrain-mlogloss:2.345002\teval-mlogloss:2.395755\n",
      "[101]\ttrain-mlogloss:2.344410\teval-mlogloss:2.395559\n",
      "[102]\ttrain-mlogloss:2.343772\teval-mlogloss:2.395353\n",
      "[103]\ttrain-mlogloss:2.343204\teval-mlogloss:2.395191\n",
      "[104]\ttrain-mlogloss:2.342655\teval-mlogloss:2.395007\n",
      "[105]\ttrain-mlogloss:2.342030\teval-mlogloss:2.394827\n",
      "[106]\ttrain-mlogloss:2.341487\teval-mlogloss:2.394641\n",
      "[107]\ttrain-mlogloss:2.340905\teval-mlogloss:2.394509\n",
      "[108]\ttrain-mlogloss:2.340355\teval-mlogloss:2.394314\n",
      "[109]\ttrain-mlogloss:2.339835\teval-mlogloss:2.394168\n",
      "[110]\ttrain-mlogloss:2.339315\teval-mlogloss:2.394035\n",
      "[111]\ttrain-mlogloss:2.338778\teval-mlogloss:2.393924\n",
      "[112]\ttrain-mlogloss:2.338189\teval-mlogloss:2.393764\n",
      "[113]\ttrain-mlogloss:2.337592\teval-mlogloss:2.393599\n",
      "[114]\ttrain-mlogloss:2.337047\teval-mlogloss:2.393447\n",
      "[115]\ttrain-mlogloss:2.336572\teval-mlogloss:2.393324\n",
      "[116]\ttrain-mlogloss:2.336011\teval-mlogloss:2.393222\n",
      "[117]\ttrain-mlogloss:2.335486\teval-mlogloss:2.393086\n",
      "[118]\ttrain-mlogloss:2.334952\teval-mlogloss:2.392964\n",
      "[119]\ttrain-mlogloss:2.334419\teval-mlogloss:2.392824\n",
      "[120]\ttrain-mlogloss:2.333892\teval-mlogloss:2.392717\n",
      "[121]\ttrain-mlogloss:2.333388\teval-mlogloss:2.392619\n",
      "[122]\ttrain-mlogloss:2.332913\teval-mlogloss:2.392542\n",
      "[123]\ttrain-mlogloss:2.332385\teval-mlogloss:2.392415\n",
      "[124]\ttrain-mlogloss:2.331899\teval-mlogloss:2.392315\n",
      "[125]\ttrain-mlogloss:2.331400\teval-mlogloss:2.392255\n",
      "[126]\ttrain-mlogloss:2.330918\teval-mlogloss:2.392140\n",
      "[127]\ttrain-mlogloss:2.330380\teval-mlogloss:2.392046\n",
      "[128]\ttrain-mlogloss:2.329919\teval-mlogloss:2.391963\n",
      "[129]\ttrain-mlogloss:2.329479\teval-mlogloss:2.391861\n",
      "[130]\ttrain-mlogloss:2.329006\teval-mlogloss:2.391796\n",
      "[131]\ttrain-mlogloss:2.328547\teval-mlogloss:2.391728\n",
      "[132]\ttrain-mlogloss:2.328103\teval-mlogloss:2.391643\n",
      "[133]\ttrain-mlogloss:2.327672\teval-mlogloss:2.391562\n",
      "[134]\ttrain-mlogloss:2.327210\teval-mlogloss:2.391462\n",
      "[135]\ttrain-mlogloss:2.326783\teval-mlogloss:2.391393\n",
      "[136]\ttrain-mlogloss:2.326368\teval-mlogloss:2.391327\n",
      "[137]\ttrain-mlogloss:2.325930\teval-mlogloss:2.391251\n",
      "[138]\ttrain-mlogloss:2.325448\teval-mlogloss:2.391195\n",
      "[139]\ttrain-mlogloss:2.324990\teval-mlogloss:2.391142\n",
      "[140]\ttrain-mlogloss:2.324560\teval-mlogloss:2.391063\n",
      "[141]\ttrain-mlogloss:2.324117\teval-mlogloss:2.390969\n",
      "[142]\ttrain-mlogloss:2.323680\teval-mlogloss:2.390896\n",
      "[143]\ttrain-mlogloss:2.323256\teval-mlogloss:2.390798\n",
      "[144]\ttrain-mlogloss:2.322818\teval-mlogloss:2.390779\n",
      "[145]\ttrain-mlogloss:2.322412\teval-mlogloss:2.390718\n",
      "[146]\ttrain-mlogloss:2.322037\teval-mlogloss:2.390658\n",
      "[147]\ttrain-mlogloss:2.321522\teval-mlogloss:2.390635\n",
      "[148]\ttrain-mlogloss:2.321113\teval-mlogloss:2.390599\n",
      "[149]\ttrain-mlogloss:2.320758\teval-mlogloss:2.390580\n",
      "[150]\ttrain-mlogloss:2.320390\teval-mlogloss:2.390490\n",
      "[151]\ttrain-mlogloss:2.319955\teval-mlogloss:2.390451\n",
      "[152]\ttrain-mlogloss:2.319562\teval-mlogloss:2.390407\n",
      "[153]\ttrain-mlogloss:2.319154\teval-mlogloss:2.390323\n",
      "[154]\ttrain-mlogloss:2.318741\teval-mlogloss:2.390298\n",
      "[155]\ttrain-mlogloss:2.318257\teval-mlogloss:2.390213\n",
      "[156]\ttrain-mlogloss:2.317906\teval-mlogloss:2.390149\n",
      "[157]\ttrain-mlogloss:2.317481\teval-mlogloss:2.390104\n",
      "[158]\ttrain-mlogloss:2.317088\teval-mlogloss:2.390071\n",
      "[159]\ttrain-mlogloss:2.316660\teval-mlogloss:2.390008\n",
      "[160]\ttrain-mlogloss:2.316246\teval-mlogloss:2.389964\n",
      "[161]\ttrain-mlogloss:2.315809\teval-mlogloss:2.389949\n",
      "[162]\ttrain-mlogloss:2.315443\teval-mlogloss:2.389898\n",
      "[163]\ttrain-mlogloss:2.315082\teval-mlogloss:2.389853\n",
      "[164]\ttrain-mlogloss:2.314659\teval-mlogloss:2.389848\n",
      "[165]\ttrain-mlogloss:2.314326\teval-mlogloss:2.389800\n",
      "[166]\ttrain-mlogloss:2.313955\teval-mlogloss:2.389819\n",
      "[167]\ttrain-mlogloss:2.313580\teval-mlogloss:2.389786\n",
      "[168]\ttrain-mlogloss:2.313233\teval-mlogloss:2.389747\n",
      "[169]\ttrain-mlogloss:2.312817\teval-mlogloss:2.389759\n",
      "[170]\ttrain-mlogloss:2.312459\teval-mlogloss:2.389726\n",
      "[171]\ttrain-mlogloss:2.312079\teval-mlogloss:2.389688\n",
      "[172]\ttrain-mlogloss:2.311761\teval-mlogloss:2.389640\n",
      "[173]\ttrain-mlogloss:2.311384\teval-mlogloss:2.389618\n",
      "[174]\ttrain-mlogloss:2.310972\teval-mlogloss:2.389592\n",
      "[175]\ttrain-mlogloss:2.310608\teval-mlogloss:2.389589\n",
      "[176]\ttrain-mlogloss:2.310262\teval-mlogloss:2.389552\n",
      "[177]\ttrain-mlogloss:2.309972\teval-mlogloss:2.389523\n",
      "[178]\ttrain-mlogloss:2.309612\teval-mlogloss:2.389503\n",
      "[179]\ttrain-mlogloss:2.309257\teval-mlogloss:2.389453\n",
      "[180]\ttrain-mlogloss:2.308938\teval-mlogloss:2.389407\n",
      "[181]\ttrain-mlogloss:2.308578\teval-mlogloss:2.389426\n",
      "[182]\ttrain-mlogloss:2.308269\teval-mlogloss:2.389411\n",
      "[183]\ttrain-mlogloss:2.307920\teval-mlogloss:2.389398\n",
      "[184]\ttrain-mlogloss:2.307587\teval-mlogloss:2.389380\n",
      "[185]\ttrain-mlogloss:2.307239\teval-mlogloss:2.389379\n",
      "[186]\ttrain-mlogloss:2.306885\teval-mlogloss:2.389355\n",
      "[187]\ttrain-mlogloss:2.306567\teval-mlogloss:2.389363\n",
      "[188]\ttrain-mlogloss:2.306259\teval-mlogloss:2.389328\n",
      "[189]\ttrain-mlogloss:2.305943\teval-mlogloss:2.389323\n",
      "[190]\ttrain-mlogloss:2.305598\teval-mlogloss:2.389300\n",
      "[191]\ttrain-mlogloss:2.305282\teval-mlogloss:2.389288\n",
      "[192]\ttrain-mlogloss:2.304955\teval-mlogloss:2.389300\n",
      "[193]\ttrain-mlogloss:2.304617\teval-mlogloss:2.389329\n",
      "[194]\ttrain-mlogloss:2.304273\teval-mlogloss:2.389300\n",
      "[195]\ttrain-mlogloss:2.303942\teval-mlogloss:2.389274\n",
      "[196]\ttrain-mlogloss:2.303636\teval-mlogloss:2.389266\n",
      "[197]\ttrain-mlogloss:2.303281\teval-mlogloss:2.389226\n",
      "[198]\ttrain-mlogloss:2.302974\teval-mlogloss:2.389234\n",
      "[199]\ttrain-mlogloss:2.302669\teval-mlogloss:2.389223\n",
      "[200]\ttrain-mlogloss:2.302382\teval-mlogloss:2.389213\n",
      "[201]\ttrain-mlogloss:2.302098\teval-mlogloss:2.389180\n",
      "[202]\ttrain-mlogloss:2.301799\teval-mlogloss:2.389183\n",
      "[203]\ttrain-mlogloss:2.301525\teval-mlogloss:2.389152\n",
      "[204]\ttrain-mlogloss:2.301217\teval-mlogloss:2.389165\n",
      "[205]\ttrain-mlogloss:2.300894\teval-mlogloss:2.389142\n",
      "[206]\ttrain-mlogloss:2.300530\teval-mlogloss:2.389121\n",
      "[207]\ttrain-mlogloss:2.300232\teval-mlogloss:2.389099\n",
      "[208]\ttrain-mlogloss:2.299904\teval-mlogloss:2.389094\n",
      "[209]\ttrain-mlogloss:2.299626\teval-mlogloss:2.389121\n",
      "[210]\ttrain-mlogloss:2.299273\teval-mlogloss:2.389099\n",
      "[211]\ttrain-mlogloss:2.298947\teval-mlogloss:2.389036\n",
      "[212]\ttrain-mlogloss:2.298645\teval-mlogloss:2.389025\n",
      "[213]\ttrain-mlogloss:2.298329\teval-mlogloss:2.389030\n",
      "[214]\ttrain-mlogloss:2.298015\teval-mlogloss:2.389044\n",
      "[215]\ttrain-mlogloss:2.297745\teval-mlogloss:2.389036\n",
      "[216]\ttrain-mlogloss:2.297417\teval-mlogloss:2.389057\n",
      "[217]\ttrain-mlogloss:2.297122\teval-mlogloss:2.389042\n",
      "[218]\ttrain-mlogloss:2.296825\teval-mlogloss:2.389035\n",
      "[219]\ttrain-mlogloss:2.296569\teval-mlogloss:2.389014\n",
      "[220]\ttrain-mlogloss:2.296222\teval-mlogloss:2.389040\n",
      "[221]\ttrain-mlogloss:2.295922\teval-mlogloss:2.389015\n",
      "[222]\ttrain-mlogloss:2.295673\teval-mlogloss:2.389042\n",
      "[223]\ttrain-mlogloss:2.295394\teval-mlogloss:2.389057\n",
      "[224]\ttrain-mlogloss:2.295089\teval-mlogloss:2.389037\n",
      "[225]\ttrain-mlogloss:2.294830\teval-mlogloss:2.389034\n",
      "[226]\ttrain-mlogloss:2.294577\teval-mlogloss:2.389045\n",
      "[227]\ttrain-mlogloss:2.294288\teval-mlogloss:2.389039\n",
      "[228]\ttrain-mlogloss:2.293984\teval-mlogloss:2.389074\n",
      "[229]\ttrain-mlogloss:2.293744\teval-mlogloss:2.389061\n",
      "[230]\ttrain-mlogloss:2.293443\teval-mlogloss:2.389079\n",
      "[231]\ttrain-mlogloss:2.293177\teval-mlogloss:2.389064\n",
      "[232]\ttrain-mlogloss:2.292882\teval-mlogloss:2.389052\n",
      "[233]\ttrain-mlogloss:2.292626\teval-mlogloss:2.389062\n",
      "[234]\ttrain-mlogloss:2.292367\teval-mlogloss:2.389050\n",
      "[235]\ttrain-mlogloss:2.292064\teval-mlogloss:2.389071\n",
      "[236]\ttrain-mlogloss:2.291833\teval-mlogloss:2.389110\n",
      "[237]\ttrain-mlogloss:2.291585\teval-mlogloss:2.389081\n",
      "[238]\ttrain-mlogloss:2.291315\teval-mlogloss:2.389096\n",
      "[239]\ttrain-mlogloss:2.291017\teval-mlogloss:2.389085\n",
      "Stopping. Best iteration:\n",
      "[219]\ttrain-mlogloss:2.296569\teval-mlogloss:2.389014\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "('Importance array: ', [('device_model', 60846), ('counts', 47964), ('installed', 39564), ('active', 28238), ('phone_brand', 19307)])\n",
      "Predict test set...\n",
      "Training time: 0.74 minutes\n",
      "LS: 2.38903\n",
      "('Writing submission: ', 'submission_2.38903411508_2016-07-29-09-41.csv')\n"
     ]
    }
   ],
   "source": [
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('device_id,F23-,F24-26,F27-28,F29-32,F33-42,F43+,M22-,M23-26,M27-28,M29-31,M32-38,M39+\\n')\n",
    "    total = 0\n",
    "    test_val = test['device_id'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(12):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def map_column(table, f):\n",
    "    labels = sorted(table[f].unique())\n",
    "    mappings = dict()\n",
    "    for i in range(len(labels)):\n",
    "        mappings[labels[i]] = i\n",
    "    table = table.replace({f: mappings})\n",
    "    return table\n",
    "\n",
    "\n",
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "\n",
    "def print_features_importance(imp):\n",
    "    for i in range(len(imp)):\n",
    "        print(\"# \" + str(imp[i][1]))\n",
    "        print('output.remove(\\'' + imp[i][0] + '\\')')\n",
    "\n",
    "\n",
    "def read_train_test():\n",
    "    # App events\n",
    "    print('Read app events...')\n",
    "    ape = pd.read_csv(\"~/百度云同步盘/dev/Kaggle/TalkingData/app_events.csv\")\n",
    "    ape['installed'] = ape.groupby(['event_id'])['is_installed'].transform('sum')\n",
    "    ape['active'] = ape.groupby(['event_id'])['is_active'].transform('sum')\n",
    "    ape.drop(['is_installed', 'is_active'], axis=1, inplace=True)\n",
    "    ape.drop_duplicates('event_id', keep='first', inplace=True)\n",
    "    ape.drop(['app_id'], axis=1, inplace=True)\n",
    "    \n",
    "    # Events\n",
    "    print('Read events...')\n",
    "    events = pd.read_csv(\"~/百度云同步盘/dev/Kaggle/TalkingData/events.csv\", dtype={'device_id': np.str})\n",
    "    events['counts'] = events.groupby(['device_id'])['event_id'].transform('count')\n",
    "    \n",
    "    # The idea here is to count the number of installed apps using the data\n",
    "    # from app_events.csv above. Also to count the number of active apps.\n",
    "    events = pd.merge(events, ape, how='left', on='event_id', left_index=True)\n",
    "\n",
    "    # Below is the original events_small table\n",
    "    # events_small = events[['device_id', 'counts']].drop_duplicates('device_id', keep='first')\n",
    "    # And this is the new events_small table with two extra features\n",
    "    events_small = events[['device_id', 'counts', 'installed', 'active']].drop_duplicates('device_id', keep='first')\n",
    "\n",
    "    # Phone brand\n",
    "    print('Read brands...')\n",
    "    pbd = pd.read_csv(\"~/百度云同步盘/dev/Kaggle/TalkingData/phone_brand_device_model.csv\", dtype={'device_id': np.str})\n",
    "    pbd.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "    pbd = map_column(pbd, 'phone_brand')\n",
    "    pbd = map_column(pbd, 'device_model')\n",
    "\n",
    "    # Train\n",
    "    print('Read train...')\n",
    "    train = pd.read_csv(\"~/百度云同步盘/dev/Kaggle/TalkingData/gender_age_train.csv\", dtype={'device_id': np.str})\n",
    "    train = map_column(train, 'group')\n",
    "    train = train.drop(['age'], axis=1)\n",
    "    train = train.drop(['gender'], axis=1)\n",
    "    train = pd.merge(train, pbd, how='left', on='device_id', left_index=True)\n",
    "    train = pd.merge(train, events_small, how='left', on='device_id', left_index=True)\n",
    "    train.fillna(-1, inplace=True)\n",
    "\n",
    "    # Test\n",
    "    print('Read test...')\n",
    "    test = pd.read_csv(\"~/百度云同步盘/dev/Kaggle/TalkingData/gender_age_test.csv\", dtype={'device_id': np.str})\n",
    "    test = pd.merge(test, pbd, how='left', on='device_id', left_index=True)\n",
    "    test = pd.merge(test, events_small, how='left', on='device_id', left_index=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "\n",
    "    # Features\n",
    "    features = list(test.columns.values)\n",
    "    features.remove('device_id')\n",
    "\n",
    "    return train, test, features\n",
    "\n",
    "\n",
    "train, test, features = read_train_test()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "test_prediction, score = run_xgb(train, test, features, 'group')\n",
    "print(\"LS: {}\".format(round(score, 5)))\n",
    "create_submission(score, test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
